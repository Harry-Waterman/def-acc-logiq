version: "3.9"

services:
  mlc-server:
    image: ghcr.io/mlc-ai/mlc-llm:latest
    container_name: mlc-llm-server
    command:
      [
        "mlc_llm",
        "serve",
        "--model",
        "${MLC_MODEL_ID:-Qwen3-0.6B-q4f16_1-MLC}",
        "--host",
        "0.0.0.0",
        "--port",
        "8080"
      ]
    environment:
      - PYTHONUNBUFFERED=1
    ports:
      - "${MLC_SERVER_PORT:-8080}:8080"
    restart: unless-stopped

  evaluator:
    build:
      context: .
    container_name: evaluation-node-app
    depends_on:
      - mlc-server
    environment:
      - NODE_ENV=production
      - DATASET_PATH=${DATASET_PATH:-/workspace/dataset/Nigerian_Fraud.csv}
      - MLC_MODEL_ID=${MLC_MODEL_ID:-Qwen3-0.6B-q4f16_1-MLC}
      - MLC_SERVER_URL=http://mlc-server:8080
      - DEFAULT_SAMPLE_SIZE=${DEFAULT_SAMPLE_SIZE:-20}
      - NUM_RUNS=${NUM_RUNS:-100}
    volumes:
      - ../..:/workspace
    working_dir: /workspace/evaluation/node-app
    command: ["npm", "run", "benchmark", "--", "--sampleSize", "${DEFAULT_SAMPLE_SIZE:-20}", "--numRuns", "${NUM_RUNS:-100}"]

